"0","# We want to minimize the cost function. Then derivate this funcion"
"0","TestGradientDescent2 <- function(iterations = 1200, learning_rate = 0.25, the_data) {"
"0","  "
"0","  # label in the last column in dataSet"
"0","  model <- gradDescentR.learn(dataSet = the_data, featureScaling = TRUE, scalingMethod = ""VARIANCE"", "
"0","                              learningMethod = ""GD"", control = list(alpha = learning_rate, maxIter = iterations), "
"0","                              seed = 1234)"
"0","  "
"0","  model"
"0","}"
"0","# How to use"
"0","TestGradientDescent2(the_data = data)"
"1","$`featureScaling`
"
"1","[1]"
"1"," TRUE"
"1","
"
"1","
"
"1","$scalingMethod
"
"1","[1]"
"1"," ""VARIANCE"""
"1","
"
"1","
"
"1","$scalingParameter
"
"1","    "
"1"," [,1]    "
"1"," [,2]    "
"1"," [,3]    "
"1","
[1,]"
"1"," 65.64427"
"1"," 66.222  "
"1"," 0.6     "
"1","
[2,]"
"1"," 19.45822"
"1"," 18.58278"
"1"," 0.492366"
"1","
"
"1","
"
"1","$`learningMethod`
"
"1","[1]"
"1"," ""GD"""
"1","
"
"1","
"
"1","$model
"
"1","    "
"1","         [,1]"
"1","      [,2]"
"1","      [,3]"
"1","
[1,]"
"1"," 1.666426e-16"
"1"," 0.5865089"
"1"," 0.5262028"
"1","
"
"1","
"
"1","$control
"
"1","$control$`alpha`
"
"1","[1]"
"1"," 0.25"
"1","
"
"1","
"
"1","$control$maxIter
"
"1","[1]"
"1"," 1200"
"1","
"
"1","
"
"1","$control$momentum
"
"1","[1]"
"1"," 0.9"
"1","
"
"1","
"
"1","$control$nBatch
"
"1","[1]"
"1"," 2"
"1","
"
"1","
"
"1","$control$lamda
"
"1","[1]"
"1"," 0"
"1","
"
"1","
"
"1","$control$innerIter
"
"1","[1]"
"1"," 10"
"1","
"
"1","
"
"1","$control$option
"
"1","[1]"
"1"," 2"
"1","
"
"1","
"
"1","$control$gammaS
"
"1","[1]"
"1"," 0.125"
"1","
"
"1","
"
"1","
"
"1","attr(,""class"")"
"1","
"
"1","[1]"
"1"," ""gradDescentRObject"""
"1","
"
"0","# Now, the exercises. Use training and test set, change the value of alpha..."
